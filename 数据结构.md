# 第一章 绪论

## 起泡排序

是一个不断对整个数组遍历的过程

![1657847419411](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657847419411.jpg)

每次都对相邻的数组进行大小比较，同时把小的放下面，大的放上面，最后不断循环这个过程，最终就会达到顺序。

## 算法的基本性质

确定性、可行性、有穷性、正确性、退化以及鲁棒性

确定算法有穷性和正确性的一个技巧：找出算法的不变性和单调性。单调性通常是指，问题的有效规模会随着算法的推进不断递减。不变性则不仅应在算法初始状态下自然满足，而且应与最终的正确性相呼应——当问题的有效规模缩减到0时，不变性应随即等价于正确性

就起泡排序而言，算法的不变性和单调性可分别概括为：经过k趟扫描交换之后，最大的前k个元素必然就位；经过k趟扫描交换之后，待求解问题的有效规模将缩减至n - k。

## 算法的复杂度（时间与空间）

### 大O记号：

(1)	对于任一常数c > 0，有O(f(n))  =  O(c·f(n))

(2)	对于任意常数a > b > 0，有O(na + nb)  =  O(na)

前一性质意味着，在大O记号的意义下，函数各项正的常系数可以忽略并等同于1。后一性质则意味着，多项式中的低次项均可忽略，只需保留最高次项。

大O记号形式表示的时间复杂度，实质上是对算法执行时间的一种保守估计，称作最坏实例或最坏情况。

### 大Ω记号

与大O记号恰好相反，大Ω记号是对算法执行效率的乐观估计——对于规模为n的任意输入，算法的运行时间都不低于Ω(g(n))

### 大Θ记号

T(n)介于Ω(g(n))与O(f(n))之间。若恰巧出现g(n) = f(n)的情况，则可以使用另一记号来表示。

![1657848276718](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657848276718.jpg)

### 常数复杂度O(1)

一般地，仅含一次或常数次基本操作的算法（如算法1.1和算法1.2）均属此类。此类算法通常不含循环、分支、子程序调用等

### 对数复杂度O(logn)

由大O记号定义，在用函数logrn界定渐进复杂度时，常底数r的具体取值无所谓。故通常不予专门标出而笼统地记作logn。

更一般地，凡运行时间可以表示和度量为T(n) = O(log^c(n)）形式的这一类算法（其中常数c >0）。均统称作“对数多项式时间复杂度的算法”。

### 线性复杂度O(n)

凡运行时间可以表示和度量为T(n) = O(n)形式的这一类算法，均统称作“线性时间复杂度算法”。也就是说，对于输入的每一单元，此类算法平均消耗常数时间。就大多数问题而言，在对输入的每一单元均至少访问一次之前，不可能得出解答。

故就此意义而言，==此类算法的效率亦足以令人满意。==

### 多项式复杂度

若运行时间可以表示和度量为T(n) = O(f(n))的形式，而且f(x)为多项式，则对应的算法称作“多项式时间复杂度算法”。

就算f(n)= 2*n^2 + n + 1，最后的O(f(n)) = O(n^2)。

项式级的运行时间成本，在实际应用中一般被认为是==可接受的或可忍受的。==

### 指数复杂度

从常数、对数、线性、平方到多项式时间复杂度，算法效率的差异还在可接受的范围。然而，在多项式与指数时间复杂度之间，却有着一道巨大的鸿沟。当问题规模较大后，指数复杂度算法的实际效率将急剧下降，计算时间之长很快就会达到==令人难以忍受==的地步。

实际上很遗憾，绝大多数计算问题并不存在多项式时间的算法。

### 输入规模导致的复杂度不同

![1657848896757](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657848896757.jpg)

接下来解释下为什么这个复杂度看着是O(n)，却被解释成了O(2^r)，这是因为==输入的参照物的不同。==

由n轮迭代组成，各需做一次累乘和一次递减，均属于基本操作，故整个算法共需O(n)时间。若以输入指数n的二进制位数r = 1 + log2n作为输入规模，则运行时间为O(2^r)。

但是一般后者描述的复杂度更好一点，严格地说，所谓待计算问题的输入规模，==应严格定义为“用以描述输入所需的空间规模”==。因此就上述两个例子而言，将输入参数n二进制展开的宽度r作为输入规模更为合理，==因为你是在对二进制数操作==。也就是说，将这两个算法的复杂度界定为O(r)和O(2r)更妥。

## 递归

### 递归基

就是递归的特殊情况，这些情况必须要单独列出来，不然会==进入死循环==

### 线性递归

类似下图，就是每一层只会内调用一次实例，线性递归的模式，往往对应==减而治之==的算法策略。

![1657849396325](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657849396325.jpg)

### 递归的复杂度分析

个算法所需的计算时间，应该等于所有递归实例的创建、执行和销毁所需的时间总和。

其中，==递归实例的创建、销毁均由操作系统负责完成==，其对应的时间成本通常可以近似为常数，不会超过递归实例中实质计算步骤所需的时间成本，故往往==均予忽略==。所以上图代码的时间复杂度为O(n)。

不难看出，在创建了最后一个递归实例（即到达递归基）时，占用的空间量达到最大，这里每一递归实例所需存放的数据，无非是调用参数（数组A的起始地址和长度n）以及用于累加总和的临时变量。这些数据各自只需常数规模的空间，其总量也应为常数。故此可知， sum()算法的空间复杂度线性正比于其递归的深度，亦即O(n)。 

### 多递归基以及多向递归

有时会有单向递归但是递归基有多种的情况，这时候要显式或隐式的把递归基表达出来

![1657849918113](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657849918113.jpg)

else隐含了两种情况，一种是当lo==hi的时候，直接不作交换，还有一种是lo>hi的时候

也会出现单递归基而多向递归的情况：

![1657849993213](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657849993213.jpg)

相较于之前的直接移位2^0,这的算法，这里是通过移位输入的n来计算2的n次方。且递归方向分为n为奇数以及n为偶数的情况。

![1657850146407](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657850146407.jpg)

这种算法降低了原本的复杂度。

### 递归消除

对于递归算法而言，递归算法所消耗的空间量主要取决于递归深度。故较之同一算法的迭代版，递归版往往需耗费更多空间，并进而影响实际的运行速度。

有鉴于此，在对运行速度要求极高、存储空间需精打细算的场合，往往应将递归算法改写成等价的非递归版本。 

在线性递归算法中，若递归调用在递归实例中恰好以最后一步操作的形式出现，则称作==尾递归。==实际上，属于尾递归形式的算法，均可以简捷地转换为等效的迭代版本。 

![1657850416107](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657850416107.jpg)

这在时间复杂度上和递归算法是一样的，但是空间复杂度变成了常数复杂度，大大降低了空间消耗

### 二分递归

求和算法的二分递归

![1657850516085](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657850516085.jpg)

算法启动后经连续m = log2n次递归调用，数组区间的长度从最初的n首次缩减至1，并到达第一个递归基。实际上，刚到达任一递归基时，已执行的递归调用总是比递归返回多m = log2n次。==（意思是每次都只会走一条分支！）==

更一般地，到达区间长度为2^k的任一递归实例之前，已执行的递归调用总是比递归返回多m-k次。因此，递归深度（即任一时刻的活跃递归实例的总数）不会超过m + 1。

鉴于每个递归实例仅需常数空间，故除数组本身所占的空间，该算法只需要O(m + 1) = O(logn)的附加空间。我们还记得，代码1.5 中线性递归版sum()算法共需O(n)的附加空间，就这一点而言，新的二分递归版sum()算法有很大改进。==（也就是将大问题分为了小问题求）==

### Fibonacci的二分递归和线性递归

![1657850806195](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657850806195.jpg)

若直接按定义进行二分递归，很明显，这样的时间复杂度是2^n^了，这样的算法==效率极其低下==

另一种思路是，直接递归两个输出，把 fib(n - 1) 和 fib(n - 2) 一起输出了。

```c++
__int64 fib(int n, __int64& prev) { //计算Fibonacci数列第n项（线性递归版）：入口形式fib(n, prev) 
if (0 == n) //若到达递归基，则 
{prev = 1; return 0; } //直接取值：fib(-1) = 1, fib(0) = 0 
else { //否则 
__int64 prevPrev; prev = fib(n - 1, prevPrev); //递归计算前两项 
return prevPrev + prev; //其和即为正解 
} 
} //用辅助变量记录前一项，返回数列的当前项，O(n) 
```

```C++
__int64 prevPrev; prev = fib(n - 1, prevPrev); //递归计算前两项 
```

上面这句话，其实类似于python里面的，返回两个结果，只是C++不能这样写，最后返回的是结果的和。

这样就把二分递归变成了线性递归，时间复杂度变成了线性的！

可以看出来，==这也是一个尾递归==，所以可以把它变成迭代版本

```C++
__int64 fibI(int n) { //计算Fibonacci数列的第n项（迭代版）：O(n) 
__int64 f = 0, g = 1; //初始化：fib(0) = 0, fib(1) = 1 
	while (0 < n--) { g += f; f = g - f; } //依据原始定义，通过n次加法和减法计算fib(n)
	return f; //返回
}
```

之前的==递归是从后往前==，这个直接从==最前面开始进行迭代==

# 第二章 向量

## 数据结构的划分

可以将各种数据结构划分为线性结构、半线性结构与非线性结构三大类。

最为基本的线性结构统称为序列（sequence），根据其中数据项的逻辑次序与其物理存储地址的对应关系不同，又可进一步地将序列区分为向量（vector）和列表（list）。

==在向量中，所有数据项的物理存放位置与其逻辑次序完全吻合==，此时的逻辑次序也称作秩（rank）；而在列表中，逻辑上相邻的数据项在物理上未必相邻，而是采用间接定址的方式通过封装后的位置（position）相互引用。 

## 数组的前驱和后继

其中，对于任何0  i < j < n，A[i]都是A[j]的前驱（predecessor），A[j]都是A[i]的后继（successor）。特别地，对于任何i ≥ 1，A[i - 1]称作A[i]的直接前驱（intermediate predecessor）;对于任何i ≤ n - 2，A[i + 1]称作A[i]的直接后继（ intermediate successor）。任一元素的所有前驱构成其前缀（prefix），所有后继构成其后缀（suffix）。

## 数组的操作时间

读取、修改等基本操作，操作都可以在常数时间内完成——只要从数组所在空间的起始地址A出发，即可根据每一元素的编号，经过一次乘法运算和一次加法运算，获得待访问元素的物理地址。

## 向量的定义

向量（vector）就是线性数组的一种抽象与泛化，它也是由具有线性次序的一组元素构成的集合V = { v0, v1, ..., vn-1 }，其中的元素分别由秩相互区分。 

各元素的秩（rank）互异，且均为[0, n)内的整数。具体地，==若元素e的前驱元素共计r个，则其秩就是r==。

## ADT接口

就是抽象数据接口，书上给出的是向量，也就是vector的接口

### 构造

vector是一个可以动态变化大小的容器，但是其本质还是由固定的数组构成的，只是比数组多了一个_size内部变量来维护长度。

其容量由私有变量_capacity指示；有效元素的数量（即向量当前的实际规模），则由__size指示。

向量中秩为r的元素，对应于内部数组中的_elem[r]，其物理地址为__elem + r 

==所以vector的构造就是先申请出一个固定大小的数组_elem[r]，然后再定义其容量和size==

### 析构

与构造函数不同，同一对象只能有一个析构函数，==不得重载==。

只需释放用于存放元素的内部数组 _ elem[]，将其占用的空间交还操作系统。_capacity和 _size之类的内部变量无需做任何处理，==它们将作为向量对象自身的一部分被系统回收，此后既无需也无法被引用==。也就是C++的类对象自动会析构这些变量。

### 如何实现动态扩容

一种可行的方法，们需要==另行申请==一个容量更大的数组B，并将原数组中的成员==集体搬迁==新的空间，此后方可顺利地插入新元素e而不致溢出。当然，原数组所占的空间，需要及时释放并归还操作系统。 如下图所示：

![1657939581490](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657939581490.jpg)

新数组的地址由操作系统分配，与原数据区没有直接的关系。这种情况下，若直接引用数组，往往会导致共同指向原数组的其它指针失效，成为野指针（wild pointer）；而经封装为向量之后，即可继续准确地引用各元素，从而有效地避免野指针的风险。 

### 可扩充向量的时间代价分析

每次扩容，元素的搬迁都需要花费额外的时间。准确地，每一次由n到2n的扩容，都需要花费O(2n) = O(n)时间——这也是最坏情况下，单次插入操作所需的时间。表面看来，这一扩容策略似乎效率很低，但这不过是一种错觉。

请注意，按照此处的约定，每花费O(n)时间实施一次扩容，数组的容量都会加倍。这就意味着，至少要再经过n次插入操作，才会因为可能溢出而再次扩容。也就是说，随着向量规模的不断扩大，在执行插入操作之前需要进行扩容的概率，也将迅速降低。故就某种==平均意义==而言，用于扩容的时间成本不至很高。

以可扩充向量为例，可以考查对该结构的连续n次（查询、插入或删除等）操作，将所有操作中用于内部数组扩容的时间累计起来，然后除以n。只要n足够大，这一平均时间就是用于扩容处理的分摊时间成本。以下我们将看到，即便排除查询和删除操作而仅考查插入操作，在可扩充向量单次操作中，用于扩容处理的==分摊时间成本也不过O(1)==。 

==以上是对翻倍扩充的分析==

早期可扩充向量多采用另一策略：一旦有必要，则追加==固定数目==的单元。实际上，无论采用的固定常数多大，在最坏情况下，此类数组单次操作的分摊时间复杂度都将高达Ω(n)

### 缩容

尽管下溢不属于必须解决的问题，但在格外关注空间利用率的场合，发生下溢时也有必要适当缩减内部数组容量。

操作和扩容类似，可以通过检测_size和数组总容量的比例来判断是否需要缩容。这里以25%作为装填因子的下限，但在实际应用中，为避免出现频繁交替扩容和缩容的情况，可以选用更低的阈值，甚至取作0。

与expand()操作类似，尽管单次shrink()操作需要线性量级的时间，==但其分摊复杂度亦为O(1)==

### 重载引用操作符

```C++
template <typename T> T& Vector<T>::operator[](Rank r) const  //重载下标操作符 
{ return _elem[r]; } // assert: 0 <= r < _size 
```

### 置乱器

置乱，顾名思义，就是打乱向量的顺序。

![1657940488045](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657940488045.jpg)

```C++
template <typename T> void permute(Vector<T>& V) { //随机置乱向量，使各元素等概率出现于每一位置 
	for (int i = V.size(); i > 0; i--) //自后向前 
		swap(V[i - 1], V[rand() % i]); //V[i - 1]与V[0, i)中某一随机元素交换 
} 
```

从理论上说，使用这里的算法permute()，不仅可以枚举出同一向量所有可能的排列，而且能够保证生成各种排列的==概率均等==。

同时可以升级该代码，变成==区间置乱==

```c++
template <typename T> void Vector<T>::unsort(Rank lo, Rank hi) { //等概率随机置乱向量区间[lo, hi) 
	T* V = _elem + lo; //将子向量_elem[lo, hi)视作另一向量V[0, hi - lo) 
	for (Rank i = hi - lo; i > 0; i--) //自后向前 
		swap(V[i - 1], V[rand() % i]); //将V[i - 1]与V[0, i)中某一元素随机交换 
} 
```

### 判等器（比对）与比较器（比较）

“判断两个对象是否相等”与“判断两个对象的相对大小”都是至关重要的操作

前者多称作“比对”操作，后者多称作“比较”操作。

之所以要提这个，是因为vector定义的元素类型不一定只是简单的int，double，可能是需要抽象对比的

这时候就需要==重载各个比较符号==了

### 无序查找

按顺序迭代查找法：就是从后往前一个一个对照，==只能找到秩最大的那个==

```c++
template <typename T> //无序向量的顺序查找：返回最后一个元素e的位置；失败时，返回lo - 1 
Rank Vector<T>::find(T const& e, Rank lo, Rank hi) const {  //assert: 0 <= lo < hi <= _size 
	while ((lo < hi--) && (e != _elem[hi])); //从后向前，顺序查找 
	return hi; //若hi < lo，则意味着失败；否则hi即命中元素的秩 
} 
```

最坏情况下，查找终止于首元素_elem[lo]，运行时间为O(hi - lo) = O(n)。

### 插入操作

```C++
template <typename T> //将e作为秩为r元素插入 
Rank Vector<T>::insert(Rank r, T const& e) { //assert: 0 <= r <= size 
	expand(); //若有必要，扩容
	for (int i = _size; i > r; i--) _elem[i] = _elem[i-1]; //自后向前，后继元素顺次后移一个单元 
	_elem[r] = e; _size++; //置入新元素并更新容量
	return r; //返回秩 
}
```

==插入之前必须首先调用expand()算法，核对是否即将溢出==

后需要将后缀_elem[r, _size)（如果非空）==整体后移==一个单元（图(c)）。这些后继元素自后向前的搬迁次序不能颠倒，否则会因元素被覆盖而造成数据丢失。在单元 _elem[r]腾出之后，方可将待插入对象e置入其中。

新插入元素越靠后（前）所需时间越短（长）。特别地，r取最大值_size时为，最好情况，只需O(1)时间；r取最小值0时为最坏情况，需要O( _size)时间。一般地，若插入位置等概率分布，则平均运行时间为==O( _size) = O(n)==（习题[2-9]），线性正比于向量的实际规模。

### 剔除操作

剔除和插入的区别在于，剔除有时需要剔除一整个区间

实现的图如下

![1657941767467](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657941767467.jpg)

```C++
template <typename T> int Vector<T>::remove(Rank lo, Rank hi) { //删除区间[lo, hi) 
    if (lo == hi) return 0; //出于效率考虑，单独处理退化情况，比如remove(0, 0) 
    while (hi < _size) _elem[lo++] = _elem[hi++]; //[hi, _size)顺次前移hi - lo个单元 
    _size = lo; //更新规模，直接丢弃尾部[lo, _size = hi)区间
    shrink(); //若有必要，则缩容
    return hi - lo; //返回被删除元素的数目
}
```

上面这个是删除区间元素的==重载接口==，下面是调用这个接口的真正的remove

```C++
template <typename T> T Vector<T>::remove(Rank r) { //删除向量中秩为r的元素，0 <= r < size 
    T e = _elem[r]; //备份被删除元素 
    remove(r, r + 1); //调用区间删除算法，等效于对区间[r, r + 1)的删除 
    return e; //返回被删除元素 
 } 
```

被删除元素在向量中的位置越靠后（前）所需时间越短（长），最好为O(1)，==最坏为O(n)== = O(_size)。

### 唯一化（除去重复元素）

```c++
template <typename T> int Vector<T>::deduplicate() { //删除无序向量中重复元素（高效版） 
    int oldSize = _size; //记录原规模 
    Rank i = 1; //从_elem[1]开始 
    while (i < _size) //自前向后逐一考查各元素_elem[i] 
       (find(_elem[i], 0, i) < 0) ? //在其前缀中寻找与之雷同者（至多一个） 
       i++ : remove(i); //若无雷同则继续考查其后继，否则删除雷同者 
    return oldSize - _size; //向量规模变化量，即被删除元素总数 
 } 
```

每步迭代所需时间为O(n)，总体复杂度应为O(n^2^)。

### 遍历并操作

这里的遍历不是简单地对元素进行一次循环即可，而是要在循环过程中==进行统一的操作==

```C++
template <typename T> void Vector<T>::traverse(void (*visit)(T&))  //利用函数指针机制的遍历 
{ for (int i = 0; i < _size; i++) visit(_elem[i]); } 
  
template <typename T> template <typename VST> //元素类型、操作器 
void Vector<T>::traverse(VST& visit)  //利用函数对象机制的遍历 
{ for (int i = 0; i < _size; i++) visit(_elem[i]); } 
```

## 有序向量

若向量S[0, n)中的所有元素不仅按线性次序存放，而且其数值大小也按此次序单调分布，则称作有序向量（sorted vector）。

序向量的定义中实际上还隐含了另一更强的先决条件：==各元素之间必须能够比较大小。==

### 有序性甄别

```C++
template <typename T> int Vector<T>::disordered() const { //返回向量中逆序相邻元素对的总数 
    int n = 0; //计数器 
    for (int i = 1; i < _size; i++) //逐一检查_size - 1对相邻元素 
       if (_elem[i - 1] > _elem[i]) n++; //逆序则计数 
    return n; //向量有序当且仅当n = 0 
 } 
```

### 唯一化

```C++
template <typename T> int Vector<T>::uniquify() { //有序向量重复元素剔除算法（高效版） 
    Rank i = 0, j = 0; //各对互异“相邻”元素的秩 
    while (++j < _size) //逐一扫描，直至末元素 
       if (_elem[i] != _elem[j]) //跳过雷同者 
          _elem[++i] = _elem[j]; //发现不同元素时，向前移至紧邻于前者右侧 
    _size = ++i; shrink(); //直接截除尾部多余元素 
    return j - i; //向量规模变化量，即被删除元素总数 
 } 
```

这是利用了有序向量的特殊性，因为==相同的元素必然相邻==

![1657944067686](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657944067686.jpg)

共需迭代n次。由此可知，uniquify()算法的时间复杂度应为O(n)，较之uniquifySlow()的O(n^2^)，效率整整提高了一个线性因子。

### 二分查找

#### ①减而治之

![1657944178581](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657944178581.jpg)

只需将目标元素e与x做一比较，即可视比较结果分==三种情况==做进一步处理：1）若e < x，则目标元素如果存在，必属于左侧子区间S[lo, mi)，故可深入其中继续查找；2）若x < e，则目标元素如果存在，必属于右侧子区间S(mi, hi)，故也可深入其中继续查找；3）若e = x，则意味着已经在此处命中，故查找随即终止。

```C++
// 二分查找算法（版本A）：在有序向量的区间[lo, hi)内查找元素e，0 <= lo <= hi <= _size 
 template <typename T> static Rank binSearch(T* A, T const& e, Rank lo, Rank hi) { 
    while (lo < hi) { //每步迭代可能要做两次比较判断，有三个分支 
       Rank mi = (lo + hi) >> 1; //以中点为轴点 
       if      (e < A[mi]) hi = mi; //深入前半段[lo, mi)继续查找 
       else if (A[mi] < e) lo = mi + 1; //深入后半段(mi, hi)继续查找 
       else                return mi; //在mi处命中 
    } //成功查找可以提前终止 
    return -1; //查找失败 
 } //有多个命中元素时，不能保证返回秩最大者；查找失败时，简单地返回-1，而不能指示失败的位置
```

每一步迭代之后无论沿着哪个方向深入，新问题的规模都将缩小一半。因此，这一策略亦称作二分查找（binary search）。 

也就是说，随着迭代的不断深入，有效的查找区间宽度将按1/2的比例以几何级数的速度递减。于是，经过至多log2(hi - lo)步迭代后，算法必然终止。鉴于每步迭代仅需常数时间，故总体时间复杂度不超过： 

O(log2(hi - lo))  =  O(logn)

#### 查找长度

以上迭代过程所涉及的计算，主要分为两类：元素的大小比较、秩的算术运算及其赋值。

而查找算法的整体效率也更主要地取决于其中所执行的元素==大小比较操作的次数==，即所谓查找长度（search length）。

![1657944427134](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657944427134.jpg)

图中的数字是根据代码，寻找一个元素所需要的比较次数，实框代表成功查找到需要的次数，虚框代表失败的次数。

==失败的情况会比成功的情况多一种==，成功的情况是abc里面的总和七个，失败只有d一行八个

各元素对应的成功查找次数为{ 4, 3, 5, 2, 5, 4, 6 } ，那么平均长度为4.14

通过数学方法分析可得对于n个元素的平均长度为：O(1.5·log2n)

#### Fibonacci查找

针对之前二分查找的不足，也就是简单的将数组二分为两半，Fibonacci查找是将数组进行==黄金分割==

![1657944743809](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657944743809.png)

具体的内容看书就行了，最后的平均查找长度是O(1.44·log2n)，效率会提高一点

#### 改进成两分支

```C++
// 二分查找算法（版本B）：在有序向量的区间[lo, hi)内查找元素e，0 <= lo <= hi <= _size 
 template <typename T> static Rank binSearch(T* A, T const& e, Rank lo, Rank hi) { 
    while (1 < hi - lo) { //每步迭代仅需做一次比较判断，有两个分支；成功查找不能提前终止 
       Rank mi = (lo + hi) >> 1; //以中点为轴点 
       (e < A[mi]) ? hi = mi : lo = mi; //经比较后确定深入[lo, mi)或[mi, hi) 
    } //出口时hi = lo + 1，查找区间仅含一个元素A[lo] 
    return (e == A[lo]) ? lo : -1 ; //查找成功时返回对应的秩；否则统一返回-1 
 } //有多个命中元素时，不能保证返回秩最大者；查找失败时，简单地返回-1，而不能指示失败的位置 
```

二分查找算法的版本A基本类似。不同之处是，在每个切分点A[mi]处，仅做一次元素比较。具体地，若目标元素小于A[mi]，则深入前端子向量A[lo, mi)继续查找；否则，深入后端子向量A[mi, hi)继续查找。 

在这一版本中，只有在向量有效区间宽度缩短至1个单元时算法才会终止，而不能如版本A那样，一旦命中就能及时返回。==因此，最好情况下的效率有所倒退。当然，作为补偿，最坏情况下的效率相应地有所提高。==实际上无论是成功查找或失败查找，版本B==各分支的查找长度更加接近==，故==整体性能更趋稳定。==

另一版本

```C++
// 二分查找算法（版本C）：在有序向量的区间[lo, hi)内查找元素e，0 <= lo <= hi <= _size 
 template <typename T> static Rank binSearch(T* A, T const& e, Rank lo, Rank hi) { 
    while (lo < hi) { //每步迭代仅需做一次比较判断，有两个分支 
       Rank mi = (lo + hi) >> 1; //以中点为轴点 
       (e < A[mi]) ? hi = mi : lo = mi + 1; //经比较后确定深入[lo, mi)或(mi, hi) 
    } //成功查找不能提前终止 
    return --lo; //循环结束时，lo为大于e的元素的最小秩，故lo - 1即不大于e的元素的最大秩 
 } //有多个命中元素时，总能保证返回秩最大者；查找失败时，能够返回失败的位置 
```

此时只能确定切分点A[mi] ≤ e，“贸然”地将A[mi]排除在进一步的查找范围之外，似乎可能因遗漏这些元素，而导致本应成功的查找以失败告终。

然而这种担心大可不必。通过数学归纳可以证明，版本C中的循环体，具有如下不变性：

==A[0, lo)中的元素皆不大于e；A[hi, n)中的元素皆大于e==

![1657945452160](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657945452160.png)

循环终止时，lo = hi。考查此时的元素A[lo - 1]和A[lo]：作为A[0, lo)内的最后一个元素，A[lo - 1]必不大于e；作为A[lo, n) = A[hi, n)内的第一个元素，A[lo]必大于e。也就是说，A[lo - 1]即是原向量中不大于e的最后一个元素。==因此在循环结束之后，无论成功与否，只需返回lo - 1即可==——这也是版本C与版本B的第三点差异。

## 排序与下界

尽管很多算法都可以优化，但有一个简单的事实却往往为人所忽略：对任一特定的应用问题，随着算法的不断改进，其效率的提高必然存在某一极限。毕竟，我们不能奢望不劳而获。这一极限不仅必然存在，而且其具体的数值，应取决于应用问题本身以及所采用的计算模型。 

一般地，任一问题在最坏情况下的最低计算成本，即为该问题的复杂度下界（lower bound）。一旦某一算法的性能达到这一下界，即意味着它已是最坏情况下最优的（worst-case optimal）。可见，尽早确定一个问题的复杂度下界，对相关算法的优化无疑会有巨大的裨益。

### 比较树

这一转化方法也可以推广并应用于其它算法。一般地，树根节点对应于算法入口处的起始状态（如此处三个苹果已做好标记）；内部节点（即非末端节点，图中以白色大圈示意）对应于过程中的某步计算，通常属于基本操作；叶节点（即末端节点，图中以黑色小圈示意）则对应于经一系列计算后某次运行的终止状态。如此借助这一树形结构，可以涵盖对应算法所有可能的执行流程。

![1657946747218](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657946747218.jpg)

算法所有可能的执行过程，都可涵盖于这一树形结构中。具体地，该树具有以下性质：
	每一内部节点各对应于一次比对（称量）操作；
	内部节点的左、右分支，分别对应于在两种比对结果（是否等重）下的执行方向；
	叶节点（或等效地，根到叶节点的路径）对应于算法某次执行的完整过程及输出；
	反过来，算法的每一运行过程都对应于从根到某一叶节点的路径。

不难理解，无论什么算法，只要其中的分支都如算法2.1那样，==完全取决于不同变量或常量的比对或比较结果==，则该算法所有可能的执行过程都可表示和概括为一棵比较树。反之，凡可如此描述的算法，都称作基于比较式算法（comparison-based algorithm），简称==CBA式算法==。比如在本书中，除散列之外的算法大多属于此类。

具体地，在一棵高度为h的二叉树中，==叶节点的数目不可能多于2h==。因此反过来，==若某一问题的输出结果不少于N种，则比较树中叶节点也不可能少于N个，树高h不可能低于log2N==，N就是例题中苹果的个数

任一CBA式排序算法所对应比较树的高度应为：Ω(nlogn)

需强调的是，这一(nlogn)下界是==针对比较树模型而言的==。事实上，还有很多不属此类的排序算法

### 起泡排序

```C++
template <typename T> bool Vector<T>::bubble(Rank lo, Rank hi) { //一趟扫描交换 
    bool sorted = true; //整体有序标志 
    while (++lo < hi) //自左向右，逐一检查各对相邻元素 
       if (_elem[lo - 1] > _elem[lo]) { //若逆序，则
          sorted = false; //意味着尚未整体有序，并需要 
          swap(_elem[lo - 1], _elem[lo]); //通过交换使局部有序 
       } 
    return sorted; //返回有序标志 
 } 
```

就是迭代扫描，时间复杂度是O(n^2^)

### 归并排序

它是第一个可以在最坏情况下依然==保持O(nlogn)运行时间==的确定性排序算法。 

![1657947063075](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1657947063075.jpg)

![image-20220716125127115](C:\Users\HUAWEI\AppData\Roaming\Typora\typora-user-images\image-20220716125127115.png)

其实它分为两步，第一步是要先对无序向量分解成单个的元素，这步其实也就O(n)，不知道为什么图要这样画，是个遍历的过程。

归并算法==只能对有序向量有用==，而==单个元素也是特殊的有序向量==。

于是从单个元素开始排序，一步一步地从1个元素变成2个元素的有序向量，再变成四个元素的有序向量。

```C++
template <typename T> //有序向量的归并 
void Vector<T>::merge(Rank lo, Rank mi, Rank hi) { //以mi为界、各自有序的子向量[lo, mi)和[mi, hi) 
    T* A = _elem + lo; //合并后的向量A[0, hi - lo) = _elem[lo, hi) 
    int lb = mi - lo; T* B = new T[lb]; //前子向量B[0, lb) = _elem[lo, mi) 
    for (Rank i = 0; i < lb; B[i] = A[i++]); //复制前子向量 
    int lc = hi - mi; T* C = _elem + mi; //后子向量C[0, lc) = _elem[mi, hi) 
    for (Rank i = 0, j = 0, k = 0; (j < lb) || (k < lc); ) { //将B[j]和C[k]中的小者续至A末尾 
       if ( (j < lb) && ( !(k < lc) || (B[j] <= C[k]) ) ) A[i++] = B[j++]; 
       if ( (k < lc) && ( !(j < lb) || (C[k] <  B[j]) ) ) A[i++] = C[k++]; 
    }
    delete [] B;
}
```

上面这个代码是==只处理一对==有序向量的代码，这个代码的复杂度仅为O(n)

请注意，借助二路归并算法可在严格少于O(nlogn)时间内完成排序的这一事实，与此前2.7.3节关于排序算法下界的结论并不矛盾。毕竟，这里的输入并非一组完全随机的元素，而==是已经划分为各自有序的两组==，故就总体而言已具有相当程度的有序性。 

根据算法构思与流程，为对长度为n的向量归并排序，需递归地对长度各为n/2的两个子向量做归并排序，再花费线性时间做一次二路归并。如此，可得以下==递推==关系： （说明用归并法其实是个嵌套的过程）

T(n)  =  ==2*T(n/2)== + O(n)

T(1)  =  O(1) 

==联立==上面两个式子可得

T(n)  =  O(nlogn)

==其实logn是分层的层数==，上图中，8个元素可以分成三层，所以最后的复杂度其实是8*3

# 第三章 列表

列表元素是“循位置访问” （call-by-position）的；也可形象地理解为通往被索引元素的链接（link），故亦称作“循链接访问”（call-by-link）。

其size()和get()等静态操作均可在常数时间内完成，而insert()和remove()等动态操作却都可能需要线性时间。究其原因，在于“各元素物理地址连续”的约定——此即所谓的==“静态存储”==策略。 

得益于这种策略，可在O(1)时间内由秩确定向量元素的物理地址；但反过来，在添加（删除）元素之前（之后），又不得不移动O(n)个后继元素。可见，==尽管如此可使静态操作的效率达到极致，但就动态操作而言，局部的修改可能引起大范围甚至整个数据结构的调整==。 为了访问秩为r的元素，我们只能顺着相邻元素之间的指针，从某一端出发逐个扫描各元素，经过r步迭代后才能确定该元素的物理存储位置。这意味着，==原先只需O(1)时间的静态操作==，此时的复杂度也将线性正比于被访问元素的秩，在最坏情况下等于元素总数n；即便在各元素被访问概率相等的情况下，==平均而言也需要O(n)时间==。

## ListNode模板类的定义(struct)

```C++
typedef int Rank; //秩 
#define ListNodePosi(T) ListNode<T>* //列表节点位置 
  
template <typename T> struct ListNode { //列表节点模板类（以双向链表形式实现） 
// 成员 
    T data; ListNodePosi(T) pred; ListNodePosi(T) succ; //数值、前驱、后继 
// 构造函数 
    ListNode() {} //针对header和trailer的构造 
    ListNode( T e, ListNodePosi(T) p = NULL, ListNodePosi(T) s = NULL) 
       : data(e), pred(p), succ(s) {} //默认构造器 
// 操作接口
   ListNodePosi(T) insertAsPred(T const& e);  //紧靠当前节点之前插入新节点 
   ListNodePosi(T) insertAsSucc(T const& e);  //紧随当前节点之后插入新节点 
}; 
```

注意，这里定义的==struct==模板而非class，且要注意#define ListNodePosi(T) ListNode<T>* 这句话。

每个listnode都在其中定义了两个和它本身一致的两个指针，分别指向前一个和后一个，同时定义了两个函数用来在前后插入指针。

两个构造函数，==第一个是NULL==，给首尾定义的。

## List模板类的定义(Class)

这里的List模板类，是用来==管理ListNode==的类，拥有许多直接对Node进行操作的方法和实例

```C++
#include "listNode.h" //引入列表节点类 
template <typename T> class List { //列表模板类

private: 
	int _size; ListNodePosi(T) header; ListNodePosi(T) trailer; //规模、头哨兵、尾哨兵
	
protected:
	void init(); //列表创建时的初始化
	int clear(); //清除所有节点 
	
public: // 构造函数
	List() { init(); } //默认 
	List(List<T> const& L);  //整体复制列表L 
	List(List<T> const& L, Rank r, int n);  //复制列表L中自第r项起的n项 
	List(ListNodePosi(T) p, int n); //复制列表中自位置p起的n项 
	
// 析构函数 
   ~List(); //释放（包含头、尾哨兵在内的）所有节点 
```

这里写的不完全，完全的去看课本，这里主要是看其内部结构的变量，其余的函数不重要。

可以用看到List类是==只包含==了一个头header和一个尾trailer的，因为这个头和尾部内部会有指针指向全体链表，所以不需要设置其余ListNode。

## 列表的构造

### 头尾结点

==私有的==头节点（header）和尾节点（trailer）始终存在，但对外并不可见。对外部可见的数据节点如果存在，则其中的第一个和最后一个节点分别称作首节点（first node）和末节点（last node）。

这类经封装之后从外部不可见的节点，称作==哨兵节点（sentinel node）==。

哨兵节点之后，==对于从外部可见的任一节点而言，其前驱和后继在列表内部都必然存在==，故可简化算法的描述与实现。此外更重要地，哨兵节点的引入，也使得相关算法不必再对各种边界退化情况做专门的处理，从而避免出错的可能。

![1658111148384](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658111148384.jpg)

### 默认构造方法

```C++
template <typename T> void List<T>::init() { //列表初始化，在创建列表对象时统一调用 
    header = new ListNode<T>; //创建头哨兵节点 
    trailer = new ListNode<T>; //创建尾哨兵节点 
    header->succ = trailer; header->pred = NULL; 
    trailer->pred = header; trailer->succ = NULL; 
    _size = 0; //记录规模 
} 
```

==直接就是将header和trailer初始化==，同时将header和trailer相连接

### 按下标查找==数据==，[ ]运算符的重载

```C++
template <typename T> //重载下标操作符，以通过秩直接访问列表节点（虽方便，效率低，需慎用） 
T& List<T>::operator[](Rank r) const { //assert: 0 <= r < size 
    ListNodePosi(T) p = first(); //从首节点出发 
    while (0 < r--) p = p->succ; //顺数第r个节点即是 
    return p->data; //目标节点，返回其中所存元素 
} 
```

相对于向量同类接口的O(1)复杂度，列表的这一==效率十分低下==——其根源在于，列表元素的存储和访问方式已与向量截然不同。诚然，==当r大于n/2时，从trailer出发沿pred指针逆行查找，可以在一定程度上减少迭代次数==，但就总体的平均效率而言，==这一改进并无实质意义==。

### 查找==元素==

```C++
template <typename T> //在无序列表内节点p（可能是trailer）的n个（真）前驱中，找到等于e的最后者 
ListNodePosi(T) List<T>::find(T const& e, int n, ListNodePosi(T) p) const { //0<=n<=rank(p)<_size 
   while (0 < n--) //对于p的最近的n个前驱，从右向左 
      if (e == (p = p->pred)->data) return p; //逐个比对，直至命中或范围越界 
   return NULL; //p越出左边界意味着区间内不含e，查找失败 
} //失败时，返回NULL 
```

这与前面查找不同的是，其返回的是ListNode的指针而非包含的值。

要注意的是，第四行中的判断语句，在判断 e == p 的同时，==直接把p指向了下一个指针==

### 前插入

```C++
template <typename T> //将e紧靠当前节点之前插入于当前节点所属列表（设有哨兵头节点header） 
ListNodePosi(T) ListNode<T>::insertAsPred(T const& e) { 
   ListNodePosi(T) x = new ListNode(e, pred, this); //创建新节点，pred和this作为其父节点和子节点 
   pred->succ = x; pred = x; //设置正向链接，这里的pred是this的pred，前一句把原pred的下一个指针换成了x，后一句把自己的pred换成了x
   return x; //返回新节点的位置 
} 
```

![1658111706345](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658111706345.jpg)

注意 ==a -> b -> c -> d== 的看图顺序

①创建新节点new，构造函数同时将其数据项置为e

②令其后继链接succ指向当前节点，令其前驱链接pred指向当前节点的前驱节点

③使new成为当前节点前驱节点的后继，使new成为当前节点的前驱（次序不能颠倒）

### 后插入

```C++
template <typename T> //将e紧随当前节点之后插入于当前节点所属列表（设有哨兵尾节点trailer） 
ListNodePosi(T) ListNode<T>::insertAsSucc(T const& e) { 
   ListNodePosi(T) x = new ListNode(e, this, succ); //创建新节点 
   succ->pred = x; succ = x; //设置逆向链接 
   return x; //返回新节点的位置 
} 
```

与前插入类似

插入的复杂度：上述两种插入操作过程，仅涉及局部的两个原有节点和一个新节点，且不含任何迭代或递归。

### 基于复制的构造

```C++
template <typename T> //列表内部方法：复制列表中自位置p起的n项 
void List<T>::copyNodes(ListNodePosi(T) p, int n) { //p合法，且至少有n-1个真后继节点 
   init(); //创建头、尾哨兵节点并做初始化 
   while(n--) { insertAsLast(p->data); p = p->succ; } //将起自p的n项依次作为末节点插入 
}
```

很简单，就是直接不断重复使用 insert 函数，并将要复制的链表一步步向后推进

### 删除

```C++
template <typename T> T List<T>::remove(ListNodePosi(T) p) { //删除合法位置p处节点，返回其数值 
   T e = p->data; //备份待删除节点的数值（假定T类型可直接赋值） 
   p->pred->succ = p->succ; p->succ->pred = p->pred; //将节点位置进行转移 
   delete p; _size--; //释放节点，更新规模 
   return e; //返回备份的数值 
} 
```

![1658112233710](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658112233710.jpg)

注意，删除算法返回的和插入不同，删除算法返回的是==被删除的值==

### 析构与清空

析构是将所有节点全部删除

清空是将除了header和trailer以外的全部清除

```C++
template <typename T> List<T>::~List() //列表析构器 
{ clear(); delete header; delete trailer; } //清空列表，释放头、尾哨兵节点 
```

```C++
template <typename T> int List<T>::clear() { //清空列表 
   int oldSize = _size; 
   while (0 < _size) remove(header->succ); //反复删除首节点，直至列表变空 
   return oldSize; 
}
```

### 唯一化

为了剔除重复元素，也是要用到remove

```C++
template <typename T> int List<T>::deduplicate() { //剔除无序列表中的重复节点 
   if (_size < 2) return 0; //平凡列表自然无重复 
   int oldSize = _size; //记录原规模 
   ListNodePosi(T) p = header; Rank r = 0; //p从首节点开始 
   while (trailer != (p = p->succ)) { //依次直到末节点
      ListNodePosi(T) q = find(p->data, r, p); //在p的r个（真）前驱中查找雷同者 
      q ? remove(q) : r++; //若的确存在，则删除之；否则秩加一 
   }//assert: 循环过程中的任意时刻，p的所有前驱互不相同
   return oldSize - _size; //列表规模变化量，即被删除元素总数 
}
```

因为find函数如果没找到，返回的是NULL，所以可以直接用 q 作为判断条件。

复杂度：与无序向量的去重算法一样，该算法总共需做O(n)步迭代。迭代中find()操作所需的时间线性正比于查找区间宽度，即当前节点的秩；由3.3.7节的分析结论，列表节点每次remove()操作仅需常数时间。因此，总体执行时间应为： 

1 + 2 + 3 + ... + n  =  n·(n + 1) / 2  =  ==O(n^2^)==

### 遍历

这里的遍历不是遍历访问，而是==遍历操作==

```C++
template <typename T> void List<T>::traverse(void (*visit)(T&)) //利用函数指针机制的遍历 
{  for (ListNodePosi(T) p = header->succ; p != trailer; p = p->succ) visit(p->data);  }  

template <typename T> template <typename VST> //元素类型、操作器 
void List<T>::traverse(VST& visit) //利用函数对象机制的遍历 
{  for (ListNodePosi(T) p = header->succ; p != trailer; p = p->succ) visit(p->data);  } 
```

## 有序列表

若列表中所有节点的逻辑次序与其大小次序完全一致，则称作有序列表（sorted list）。为保证节点之间可以定义次序，依然假定元素类型T直接支持大小比较，或已重载相关操作符。与有序向量一致地，这里依然约定采用非降次序。

### 唯一化

```C++
template <typename T> int List<T>::uniquify() { //成批剔除重复元素，效率更高 
   if (_size < 2) return 0; //平凡列表自然无重复 
   int oldSize = _size; //记录原规模 
   ListNodePosi(T) p; ListNodePosi(T) q; //依次指向紧邻的各对节点 
   for (p = header, q = p->succ; trailer != q; p = q, q = q->succ) //从自左向右扫描 
      if (p->data == q->data) { remove(q); q = p; } //若p和q雷同，则删除后者 
   return oldSize - _size; //列表规模变化量，即被删除元素总数 
} 
```

对于有序列表，就不需要重复迭代两次了，用双指针法即可，所以复杂度只有O(n)

==这里的for循环很厉害，直接一行把所有操作都搞定了==

注意，这里的是删除==重复的后一项==，所以最后要把q变成p。

### 查找

```C++
template <typename T> //在有序列表内节点p（可能是trailer）的n个（真）前驱中，找到不大于e的最后者 
ListNodePosi(T) List<T>::search(T const& e, int n, ListNodePosi(T) p) const { 
// assert: 0 <= n <= rank(p) < _size 
   while (0 <= n--) //对于p的最近的n个前驱，从右向左逐个比较 
      if (((p = p->pred)->data) <= e) break; //直至命中、数值越界或范围越界 
// assert: 至此位置p必符合输出语义约定——尽管此前最后一次关键码比较可能没有意义（等效于与-inf比较） 
   return p; //返回查找终止的位置 
} //失败时，返回区间左边界的前驱（可能是header）——调用者可通过valid()判断成功与否 
```

由于列表的特殊性，只能从头到尾查找，所以==有序列表的查找方法和无序列表是一样的==。

但是！这里的search是会找到==不大于e的最后者==，这是为了后面的排序器做准备

## 排序器

### 插入排序

插入排序（insertionsort）算法适用于包括向量与列表在内的任何序列结构。

算法的思路可简要描述为：始终将整个序列视作并切分为两部分：==有序的前缀==，==无序的后缀==；

通过迭代，反复地将后缀的首元素转移至前缀中。由此亦可看出插入排序算法的不变性：

==在任何时刻，相对于当前节点e = S[r]，前缀S[0, r)总是已有序==

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658113081053.jpg" alt="1658113081053" style="zoom:50%;" />

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658113104090.jpg" alt="1658113104090" style="zoom:50%;" />

```C++
template <typename T> //列表的插入排序算法：对起始于位置p的n个元素排序 
void List<T>::insertionSort(ListNodePosi(T) p, int n) { //valid(p) && rank(p) + n <= size 
   for (int r = 0; r < n; r++) { //逐一为各节点 
      insertAfter(search(p->data, r, p), p->data); //查找适当的位置并插入 
      p = p->succ; remove(p->pred); //转向下一节点 
   } 
} 
```

这里的search==是有序向量==的查找，能返回不大于p->data的列表位置

### 选择排序

与插入排序类似，该算法也将序列划分为无序前缀和有序后缀两部分；此外，还要求前缀不大于后后缀。如此，每次只需从前缀中选出最大者，并作为最小元素转移至后缀中，即可使有序部分的范围不断扩张。 

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658113726612.jpg" alt="1658113726612" style="zoom:50%;" />

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658113746563.jpg" alt="1658113746563" style="zoom:50%;" />

```C++
template <typename T> //列表的选择排序算法：对起始于位置p的n个元素排序 
void List<T>::selectionSort(ListNodePosi(T) p, int n) { //valid(p) && rank(p) + n <= size 
   ListNodePosi(T) head = p->pred; ListNodePosi(T) tail = p; 
   for (int i = 0; i < n; i++) tail = tail->succ; //待排序区间为(head, tail) 
   while (1 < n) { //在至少还剩两个节点之前，在待排序区间内 
      ListNodePosi(T) max = selectMax(head->succ, n); //找出最大者（歧义时后者优先） 
      insertBefore(tail, remove(max)); //将其移至无序区间末尾（作为有序区间新的首元素） 
      tail = tail->pred; n--; 
   } 
}
```

其中的selectMax()接口用于在无序列表中定位最大节点：

```C++
template <typename T> //从起始于位置p的n个元素中选出最大者 
ListNodePosi(T) List<T>::selectMax(ListNodePosi(T) p, int n) { 
   ListNodePosi(T) max = p; //最大者暂定为首节点p 
   for (ListNodePosi(T) cur = p; 1 < n; n--) //从首节点p出发，将后续节点逐一与max比较 
       if (!lt((cur = cur->succ)->data, max->data)) //若当前元素不小于max，则 
          max = cur; //更新最大元素位置记录 
   return max;
}
```

这里selectMax函数，==重新创建了个cur指针来代替p==，这是因为，p在函数外仍需要使用，如果这时候不用cur的话，p会被改变，在外面就用不了了。

无论输入序列中各元素的大小次序如何，以上n次selectMax()调用的累计耗时总是O(n^2^）。因此与插入排序算法不同，以上选择排序算法的时间复杂度为固定的O(n^2^)。也就是说，其最好和最坏情况下的渐进效率相同。

### 归并排序

==有序==列表的归并代码

```c++
template <typename T> //有序列表的归并：当前列表中自p起的n个元素，与列表L中自q起的m个元素归并 
void List<T>::merge(ListNodePosi(T)& p, int n, List<T>& L, ListNodePosi(T) q, int m) { 
// assert:  this.valid(p) && rank(p) + n <= size && this.sorted(p, n) 
//          L.valid(q) && rank(q) + m <= L._size && L.sorted(q, m) 
// 注意：在归并排序之类的场合，有可能 this == L && rank(p) + n = rank(q) 
   ListNodePosi(T) pp = p->pred; //借助前驱（可能是header），以便返回前 ... 
   while (0 < m) //在q尚未移出区间之前 
      if ((0 < n) && (p->data <= q->data)) //若p仍在区间内且v(p) <= v(q)，则 
      	  { if (q == (p = p->succ)) break; n--; } //将p替换为其直接后继（等效于将p归入合并的列表） 
      else //若p已超出右界或v(q) < v(p)，则 
          { insertBefore(p, L.remove((q = q->succ)->pred)); m--; } //将q转移至p之前 
   p = pp->succ; //确定归并后区间的（新）起点 
}
```

总体而言，共需O(n + m)时间，线性正比于两个子列表的长度之和。

有了merge后，就可以使用对==无序序列的归并==了，用的是==递归==算法

```C++
template <typename T> //列表的归并排序算法：对起始于位置p的n个元素排序 
void List<T>::mergeSort(ListNodePosi(T)& p, int n) { //valid(p) && rank(p) + n <= size 
   if (n < 2) return; //若待排序范围已足够小，则直接返回；否则... 
   int m = n >> 1; //以中点为界 
   ListNodePosi(T) q = p; for (int i = 0; i < m; i++) q = q->succ; //均分列表 
   mergeSort(p, m); mergeSort(q, n - m); //对前、后子列表分别排序，这里是一步步递归，最后返回p和q都是排序好的列表
   merge(p, m, *this, q, n - m); //归并 
} //注意：排序后，p依然指向归并后区间的（新）起点 
```

根据该算法的流程，为对长度为n的列表做归并排序，首先需要花费线性时间确定居中的切分节点，然后递归地对长度均为n/2的两个子列表做归并排序，最后还需花费线性的时间做二路归并。

因此，仿照对向量归并排序算法的分析方法，同样可知其复杂度应为O(nlogn)。

# 第四章 栈与队列

相对于一般的序列结构，栈与队列的数据操作范围仅限于逻辑上的特定某端。然而，得益于其简洁性与规范性，它们既成为构建更复杂、更高级数据结构的基础，同时也是算法设计的基本出发点，甚至常常作为标准配置的基本数据结构以硬件形式直接实现。

## 栈

栈（stack）是存放数据对象的一种特殊容器，其中的数据元素按线性的逻辑次序排列。

不过，尽管栈结构也支持对象的插入和删除操作，但其操作的范围仅限于栈的某一特定端。也就是说，若约定新的元素只能从某一端插入其中，则反过来也只能从这一端删除已有的元素。禁止操作的另一端，称作==盲端==。

栈中可操作的一端更多地称作==栈顶==（stack top），而另一无法直接操作的盲端则更多地称作==栈底==（stack bottom）

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658118039808.jpg" alt="1658118039808" style="zoom:67%;" />

上图是栈的一些基本操作

栈的类定义可以如下

```C++
#include "../Vector/Vector.h" //以向量为基类，派生出栈模板类 
template <typename T> class Stack: public Vector<T> { //将向量的首/末端作为栈底/顶 
public: //size()、empty()以及其它开放接口，均可直接沿用 
   void push(T const& e) { insert(size(), e); }  //入栈：等效于将新元素作为向量的末元素插入 
   T pop() { return remove(size() - 1); } //出栈：等效于删除向量的末元素 
   T& top() { return (*this)[size() - 1]; } //取顶：直接返回向量的末元素 
};
```

## 栈与递归

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658118148519.jpg" alt="1658118148519" style="zoom:67%;" />

调用栈的基本单位是帧（frame）。每次函数调用时，都会相应地创建一帧。

若在该函数返回之前又发生新的调用，则同样地要将与新函数对应的一帧压入栈中，成为新的栈顶。

函数一旦运行完毕，对应的帧随即弹出，运行控制权将被交还给该函数的上层调用函数，并按照该帧中记录的返回地址确定在二进制程序中继续执行的位置。 

### 避免递归

系统在后台隐式地维护调用栈的过程中，难以区分哪些参数和变量是对计算过程有实质作用的，更无法以通用的方式对它们进行优化，因此不得不将描述调用现场的所有参数和变量悉数入栈。再加上每一帧都必须保存的执行返回地址以及前一帧起始位置，往往导致程序的空间效率不高甚至极低；同时，隐式的入栈和出栈操作也会令实际的运行时间增加不少。 

因此==在追求更高效率的场合，应尽可能地避免递归==，尤其是过度的递归。

## 栈的典型应用

### 逆序输出

![1658118277450](C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658118277450.jpg)

例如在进制的计算中，要从第一位算到右边的最后一位，但是最后输出的时候却要先从最后一位进行输出，这时候就可以用到栈

### 递归嵌套

具有==自相似性的问题==多可嵌套地递归描述，但因分支位置和嵌套深度并不固定，其递归算法的复杂度不易控制。栈结构及其操作天然地具有递归嵌套性，故可用以高效地解决这类问题。

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658118388070.jpg" alt="1658118388070" style="zoom:67%;" />

书上用的是栈混洗来代表这个例子

### 括号匹配

这个比较麻烦，感觉看了也没啥用，建议自己查阅课本

### 延迟缓冲

在一些应用问题中，输入可分解为多个单元并通过迭代依次扫描处理，但过程中的各步计算往往滞后于扫描的进度，需要待到必要的信息已完整到一定程度之后，才能作出判断并实施计算。在这类场合，栈结构则可以扮演数据缓冲区的角色。 

书上给的例子是判断符号优先级的例子，看看就行

### 逆波兰表达式

看看就行了，感觉也没啥用

## 试探回溯法

这个也比较麻烦，讲了一种算法的方法，就是通过不断试错，最后总会输出正确的结果，主要讲解了如何==利用栈来记录以及回溯这个过程==，了解一个思想。

## 队列

与栈一样，队列（queue）也是存放数据对象的一种容器，其中的数据对象也按线性的逻辑次序排列。队列结构同样支持对象的插入和删除，但两种操作的范围分别被限制于队列的两端.

若约定新对象只能从某一端插入其中，则只能从另一端删除已有的元素。允许取出元素的一端称作==队头==（front），而允许插入元素的另一端称作==队尾==（rear）。 

<img src="C:\Users\HUAWEI\Desktop\笔记\数据结构图片\1658118693933.jpg" alt="1658118693933" style="zoom:67%;" />

```C++
#include "../List/List.h" //以List为基类 
template <typename T> class Queue: public List<T> { //队列模板类（继承List原有接口） 
public: //size()、empty()以及其它开放接口均可直接沿用 
   void enqueue(T const& e) { insertAsLast(e); } //入队：尾部插入 
   T dequeue() { return remove(first()); } //出队：首部删除 
   T& front() { return first()->data; } //队首 
}; 
```

## 队列的应用

循环分配器：就是分配资源的策略，先分配到资源并使用的要先退出。

银行服务模拟：
